<!DOCTYPE html>
  
  
  
  
   <html class="no-js"> 

  <head lang="en-us">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,maximum-scale=1">
    <meta http-equiv="X-UA-Compatible" content="IE=10" />
   <link rel="stylesheet" href="../../stylesheets/bootstrap.min.css">
    <title> - sparklyr: R interface for Apache Spark</title>
    <meta name="generator" content="Hugo 0.20" />

    
    <meta name="description" content="A website built through Hugo and blogdown (and gitdown).">
    
    <link rel="canonical" href="../../documents/perf_1b/">
    

    <meta property="og:url" content="/documents/perf_1b/">
    <meta property="og:title" content="sparklyr: R interface for Apache Spark">
    <meta property="og:image" content="">
    <meta name="apple-mobile-web-app-title" content="sparklyr: R interface for Apache Spark">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

    <link rel="shortcut icon" type="image/x-icon" href="../../images/favicon.ico">
    <link rel="icon" type="image/x-icon" href="../../images/favicon.ico">

    <link rel="stylesheet" href="../../stylesheets/fonts.css">
    <link rel="stylesheet" href="../../stylesheets/application.css">
    <link rel="stylesheet" href="../../stylesheets/temporary.css">
    <link rel="stylesheet" href="../../stylesheets/palettes.css">
    <link rel="stylesheet" href="../../stylesheets/highlight/highlight.css">

    
    
    
    <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Roboto:400,700|Roboto&#43;Mono">
    <style>
      body, input {
        font-family: 'Roboto', Helvetica, Arial, sans-serif;
      }
      pre, code {
        font-family: 'Roboto Mono', 'Courier New', 'Courier', monospace;
      }
    </style>

    
    <script src="../../javascripts/modernizr.js"></script>

    

  </head>
  <body class="palette-primary-rstudio-dark palette-accent-orange">




<div class="backdrop">
	<div class="backdrop-paper"></div>
</div>

<input class="toggle" type="checkbox" id="toggle-drawer">
<input class="toggle" type="checkbox" id="toggle-search">
<label class="toggle-button overlay" for="toggle-drawer"></label>

<header class="header">
	
  <div class="bar default">
    <div class="button button-menu" role="button" aria-label="Menu">
      <label class="toggle-button icon icon-menu" for="toggle-drawer">
        <span></span>
      </label>
    </div>

    <div>
      <h1><a href="../../">sparklyr: R interface for Apache Spark</a></h1>
    </div>


    
    <div class="button button-twitter" role="button" aria-label="Twitter">
       <a href="https://twitter.com/rstudio" title="@rstudio on Twitter" target="_blank" class="toggle-button icon icon-twitter"></a>
    </div>
    

    
    <div class="button button-github" role="button" aria-label="GitHub">
      <a href="https://github.com/rstudio/sparklyr" title="@rstudio/sparklyr on GitHub" target="_blank" class="toggle-button icon icon-github"></a>
    </div>
    
    
   </div>

</header>

<main class="main">
	<div class="drawer">
		<nav aria-label="Navigation">

  <div class="scrollable">
    <div class="wrapper">
      

      <div class="toc">
        
        <ul>
          





<li>
  
    



<a  title="Reference" href="../../reference/">
	
	Reference
</a>


  
</li>



<li>
  
    



<a  title="Documents" href="../../documents/">
	
	Documents
</a>


  
</li>



<li>
  
    



<a  title="News" href="../../news/">
	
	News
</a>


  
</li>


        </ul>
        

        
      </div>
    </div>
  </div>
</nav>

	</div>

	<article class="article">
		<div class="wrapper">
		  <h1> </h1>
			

<h1 id="spark-performance-1b-rows">Spark Performance: 1B Rows</h1>

<h2 id="setup">Setup</h2>

<pre><code class="language-r">sparklyr:::spark_install(version = &quot;2.0.0-preview&quot;, reset = TRUE, logging = &quot;WARN&quot;)
</code></pre>

<h2 id="initialization">Initialization</h2>

<pre><code class="language-r">library(sparklyr)
library(dplyr)
</code></pre>

<pre><code>## 
## Attaching package: 'dplyr'

## The following objects are masked from 'package:stats':
## 
##     filter, lag

## The following objects are masked from 'package:base':
## 
##     intersect, setdiff, setequal, union
</code></pre>

<pre><code class="language-r">library(ggplot2)

parquetName &lt;- &quot;billion.parquet&quot;
parquetPath &lt;- file.path(getwd(), parquetName)

if (dir.exists(parquetPath)) {
  unlink(parquetPath, recursive = TRUE)
}

config &lt;- spark_config()
  config[[&quot;sparklyr.shell.driver-memory&quot;]] &lt;- &quot;12G&quot;
  config[[&quot;sparklyr.shell.executor-memory&quot;]] &lt;- &quot;12G&quot;
  config[[&quot;spark.executor.memory&quot;]] &lt;- &quot;12G&quot;
  
sc &lt;- spark_connect(master = &quot;local&quot;, config = config)

billion &lt;- invoke_new(sc, &quot;java.math.BigInteger&quot;, &quot;1000000000&quot;) %&gt;%
  invoke(&quot;longValue&quot;)

hive_context(sc) %&gt;%
  invoke(&quot;range&quot;, as.integer(billion)) %&gt;%
  invoke(&quot;toDF&quot;) %&gt;%
  invoke(&quot;write&quot;) %&gt;%
  invoke(&quot;save&quot;, parquetName)
</code></pre>

<pre><code>## NULL
</code></pre>

<pre><code class="language-r">spark_disconnect(sc)

spark_conf &lt;- function(ses, config, value) {
  ses %&gt;%
    invoke(&quot;conf&quot;) %&gt;%
    invoke(&quot;set&quot;, config, value)
}

logResults &lt;- function(label, test) {
  runTimes &lt;- lapply(seq_len(3), function(idx) {
    runTime &lt;- system.time({
      sum &lt;- test()
    })
    
    as.data.frame(list(
      label = label,
      time = runTime[[3]],
      sum = sum))
  })
  
  runTimes &lt;- do.call(rbind, runTimes)
  
  as.data.frame(list(
    label = label,
    min = min(runTimes$time),
    max = max(runTimes$time),
    mean = mean(runTimes$time)
  ))
}

sparkTest &lt;- function(test, loadIntoDf = TRUE, loadData = TRUE) {
  sc &lt;- spark_connect(master = &quot;local&quot;,
                      version = &quot;2.0.0-preview&quot;,
                      config = config)
  
  ses &lt;- hive_context(sc)
  df &lt;- NULL
  
  if (loadData) {
    if (loadIntoDf) {
      df &lt;- ses %&gt;%
        invoke(&quot;read&quot;) %&gt;%
        invoke(&quot;parquet&quot;, list(parquetPath)) %&gt;%
        invoke(&quot;repartition&quot;, as.integer(parallel::detectCores()))
      
      df %&gt;%
        invoke(&quot;cache&quot;) %&gt;%
        invoke(&quot;count&quot;)
    } else {
      invisible(
        spark_read_parquet(sc, &quot;billion&quot;, parquetPath, repartition = parallel::detectCores())
      )
    }
  }
  
  result &lt;- test(sc, ses, df)
  
  spark_disconnect(sc)
  result
}
</code></pre>

<h2 id="tests">Tests</h2>

<h3 id="sum-range-from-formula">Sum range from formula</h3>

<pre><code class="language-r">spark_sum_range &lt;- function(sc, ses, df) {
  billion &lt;- invoke_new(sc, &quot;java.math.BigInteger&quot;, &quot;1000000000&quot;) %&gt;%
    invoke(&quot;longValue&quot;)
  
  result &lt;- ses %&gt;%
    invoke(&quot;range&quot;, as.integer(billion)) %&gt;%
    invoke(&quot;toDF&quot;, list(&quot;x&quot;)) %&gt;%
    invoke(&quot;selectExpr&quot;, list(&quot;sum(x)&quot;))
    
  invoke(invoke(result, &quot;collect&quot;)[[1]], &quot;get&quot;, as.integer(0))
}
</code></pre>

<h3 id="sum-range-from-parquet">Sum range from parquet</h3>

<pre><code class="language-r">spark_sum_range_parquet &lt;- function(sc, ses, df) {
  df &lt;- invoke(hive_context(sc), &quot;read&quot;) %&gt;%
    invoke(&quot;parquet&quot;, list(parquetPath))
    
  result &lt;- invoke(df, &quot;selectExpr&quot;, list(&quot;sum(id)&quot;)) %&gt;%
    invoke(&quot;collect&quot;)
  
  invoke(result[[1]], &quot;get&quot;, as.integer(0))
}
</code></pre>

<h3 id="sum-range-from-memory">Sum range from memory</h3>

<pre><code class="language-r">spark_sum_range_mem &lt;- function(sc, ses, df) {
  result &lt;- df %&gt;%
    invoke(&quot;selectExpr&quot;, list(&quot;sum(id)&quot;)) %&gt;%
    invoke(&quot;collect&quot;)
  
  invoke(result[[1]], &quot;get&quot;, as.integer(0))
}
</code></pre>

<h3 id="sum-range-using-sparklyr">Sum range using sparklyr</h3>

<pre><code class="language-r">spark_sum_range_sparklyr &lt;- function(sc, ses, df) {
  tbl(sc, &quot;billion&quot;) %&gt;%
    summarise(total = sum(id)) %&gt;%
    collect
}
</code></pre>

<h3 id="sum-range-using-sparkr-sql">Sum range using SparkR SQL</h3>

<pre><code class="language-r">spark_sum_range_sparkr_sql_prepare &lt;- function() {
  installInfo &lt;- sparklyr:::spark_install_info(sparkVersion = &quot;2.0.0-preview&quot;, hadoopVersion = &quot;2.6&quot;)
  
  Sys.setenv(SPARK_HOME = installInfo$sparkVersionDir)
  library(SparkR, lib.loc = c(file.path(Sys.getenv(&quot;SPARK_HOME&quot;), &quot;R&quot;, &quot;lib&quot;)))
  scR &lt;- sparkR.init(master = &quot;local[*]&quot;, sparkEnvir = list(spark.driver.memory=&quot;12G&quot;))
  sqlContextR &lt;- sparkRSQL.init(scR)
  df &lt;- loadDF(sqlContextR, parquetPath, &quot;parquet&quot;)
  df &lt;- repartition(df, parallel::detectCores())
  
  registerTempTable(df, &quot;billion&quot;)
  
  sql(sqlContextR, &quot;CACHE TABLE billion&quot;)
  collect(sql(sqlContextR, &quot;SELECT count(*) FROM billion&quot;))
  
  sqlContextR
}

spark_sum_range_sparkr_sql &lt;- function(sqlContextR) {
  collect(sql(sqlContextR, &quot;SELECT sum(*) FROM billion&quot;))
}

spark_sum_range_sparkr_terminate &lt;- function() {
  sparkR.stop()
  detach(name = &quot;package:SparkR&quot;)
}
</code></pre>

<h3 id="sum-range-using-sparkr-native">Sum range using SparkR Native</h3>

<pre><code class="language-r">spark_sum_range_sparkr_native_prepare &lt;- function() {
  installInfo &lt;- sparklyr:::spark_install_info(sparkVersion = &quot;2.0.0-preview&quot;, hadoopVersion = &quot;2.6&quot;)
  
  Sys.setenv(SPARK_HOME = installInfo$sparkVersionDir)
  library(SparkR, lib.loc = c(file.path(Sys.getenv(&quot;SPARK_HOME&quot;), &quot;R&quot;, &quot;lib&quot;)))
  scR &lt;- sparkR.init(master = &quot;local[*]&quot;, sparkEnvir = list(spark.driver.memory=&quot;12G&quot;))
  sqlContextR &lt;- sparkRSQL.init(scR)
  
  df &lt;- loadDF(sqlContextR, parquetPath, &quot;parquet&quot;)
  df &lt;- repartition(df, parallel::detectCores())
  cache(df)
  count(df)
  
  df
}

spark_sum_range_sparkr_native &lt;- function(df) {
  collect(summarize(df, total = sum(df$id)))
}
</code></pre>

<h3 id="sum-range-using-dplyr">Sum range using dplyr</h3>

<pre><code class="language-r">spark_sum_range_dplyr_prepare &lt;- function() {
  df &lt;- as.data.frame(as.numeric(seq_len(1000000000)))
  colnames(df) &lt;- c(&quot;x&quot;)
  head(df)
  df
}

spark_sum_range_dplyr &lt;- function(df) {
  df %&gt;% summarise(sum(x))
}
</code></pre>

<h2 id="results">Results</h2>

<h3 id="sum-range-from-formula-using-1-6">Sum range from formula using 1.6</h3>

<pre><code class="language-r">runOldCode &lt;- sparkTest(function(sc, ses, df) {
  logResults(&quot;1.6.1 Code&quot;, function() {
    spark_conf(ses, &quot;spark.sql.codegen.wholeStage&quot;, &quot;false&quot;)
    spark_sum_range(sc, ses, df)
  })
}, loadData = FALSE)
</code></pre>

<h3 id="sum-range-from-formula-using-2-0">Sum range from formula using 2.0</h3>

<pre><code class="language-r">runCode &lt;- sparkTest(function(sc, ses, df) {
  logResults(&quot;2.0.0 Code&quot;, function() {
    spark_conf(ses, &quot;spark.sql.codegen.wholeStage&quot;, &quot;true&quot;)
    spark_sum_range(sc, ses, df)
  })
}, loadData = FALSE)
</code></pre>

<h3 id="sum-range-from-parquet-1">Sum range from parquet</h3>

<pre><code class="language-r">runParquet &lt;- sparkTest(function(sc, ses, df) {
  logResults(&quot;2.0.0 Parquet&quot;, function() {
    spark_conf(ses, &quot;spark.sql.codegen.wholeStage&quot;, &quot;true&quot;)
    sum &lt;- spark_sum_range_parquet(sc, ses, df)
  })
})
</code></pre>

<h3 id="sum-range-from-memory-1">Sum range from memory</h3>

<pre><code class="language-r">runInMem &lt;- sparkTest(function(sc, ses, df) {
  logResults(&quot;2.0.0 In-Mem&quot;, function() {
    spark_conf(ses, &quot;spark.sql.codegen.wholeStage&quot;, &quot;true&quot;)
    sum &lt;- spark_sum_range_mem(sc, ses, df)
  })
})
</code></pre>

<h3 id="sum-range-using-sparklyr-1">Sum range using sparklyr</h3>

<pre><code class="language-r">runSparklyr &lt;- sparkTest(function(sc, ses, df) {
  logResults(&quot;2.0.0 sparklyr&quot;, function() {
    spark_conf(ses, &quot;spark.sql.codegen.wholeStage&quot;, &quot;true&quot;)
    sum &lt;- spark_sum_range_sparklyr(sc, ses, df)
  })
}, loadIntoDf = FALSE)
</code></pre>

<h3 id="sum-range-using-sparkr-sql-1">Sum range using SparkR SQL</h3>

<pre><code class="language-r">sqlContextR &lt;- spark_sum_range_sparkr_sql_prepare()
</code></pre>

<pre><code>## 
## Attaching package: 'SparkR'

## The following objects are masked from 'package:dplyr':
## 
##     arrange, between, collect, contains, count, cume_dist,
##     dense_rank, desc, distinct, explain, filter, first, group_by,
##     intersect, lag, last, lead, mutate, n, n_distinct, ntile,
##     percent_rank, rename, row_number, sample_frac, select, sql,
##     summarize

## The following objects are masked from 'package:stats':
## 
##     cov, filter, lag, na.omit, predict, sd, var, window

## The following objects are masked from 'package:base':
## 
##     as.data.frame, colnames, colnames&lt;-, drop, endsWith,
##     intersect, rank, rbind, sample, startsWith, subset, summary,
##     transform

## Launching java with spark-submit command /Users/javierluraschi/Library/Caches/spark/spark-2.0.0-preview-bin-hadoop2.6/bin/spark-submit   --driver-memory &quot;12G&quot; sparkr-shell /var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T//RtmpcEA7DC/backend_port6ce43c5fb478
</code></pre>

<pre><code class="language-r">runSparkRSQL &lt;- logResults(&quot;2.0.0 SparkR SQL&quot;, function() {
  sum &lt;- spark_sum_range_sparkr_sql(sqlContextR)
})
spark_sum_range_sparkr_terminate()
</code></pre>

<h3 id="sum-range-using-sparkr-native-1">Sum range using SparkR native</h3>

<pre><code class="language-r">dfSparkR &lt;- spark_sum_range_sparkr_native_prepare()
</code></pre>

<pre><code>## 
## Attaching package: 'SparkR'

## The following objects are masked from 'package:dplyr':
## 
##     arrange, between, collect, contains, count, cume_dist,
##     dense_rank, desc, distinct, explain, filter, first, group_by,
##     intersect, lag, last, lead, mutate, n, n_distinct, ntile,
##     percent_rank, rename, row_number, sample_frac, select, sql,
##     summarize

## The following objects are masked from 'package:stats':
## 
##     cov, filter, lag, na.omit, predict, sd, var, window

## The following objects are masked from 'package:base':
## 
##     as.data.frame, colnames, colnames&lt;-, drop, endsWith,
##     intersect, rank, rbind, sample, startsWith, subset, summary,
##     transform

## Launching java with spark-submit command /Users/javierluraschi/Library/Caches/spark/spark-2.0.0-preview-bin-hadoop2.6/bin/spark-submit   --driver-memory &quot;12G&quot; sparkr-shell /var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T//RtmpcEA7DC/backend_port6ce4693d1755
</code></pre>

<pre><code class="language-r">runSparkRNative &lt;- logResults(&quot;2.0.0 SparkR Native&quot;, function() {
  sum &lt;- spark_sum_range_sparkr_native(dfSparkR)
})
spark_sum_range_sparkr_terminate()
</code></pre>

<h3 id="sum-range-using-dplyr-1">Sum range using dplyr</h3>

<pre><code class="language-r">dplyrDf &lt;- spark_sum_range_dplyr_prepare()
runDplyr &lt;- logResults(&quot;dplyr&quot;, function() {
  sum &lt;- spark_sum_range_dplyr(dplyrDf)
})
dplyrDf &lt;- NULL
</code></pre>

<h2 id="results-1">Results</h2>

<pre><code class="language-r">allRuns &lt;- lapply(
  list(
    runOldCode,
    runCode,
    runParquet,
    runInMem,
    runSparklyr,
    runSparkRSQL,
    runSparkRNative,
    runDplyr
  ),
  function(e) {
    colnames(e) &lt;- c(&quot;label&quot;, &quot;min&quot;, &quot;max&quot;, &quot;mean&quot;)
    e
  })
results &lt;- do.call(&quot;rbind&quot;, allRuns)
</code></pre>

<h3 id="results-chart">Results chart</h3>

<pre><code class="language-r">results %&gt;% 
  ggplot(aes(label, mean)) +
  geom_bar(stat = &quot;identity&quot;) +
  geom_text(aes(label = round(mean, 2)), vjust = -0.2, hjust = 1.1) +
  geom_errorbar(aes(ymin = min, ymax = max), width = 0.1)
</code></pre>

<p><img src="perf_1b_files/figure-markdown_github/unnamed-chunk-10-1.png" alt="" /></p>

<h3 id="results-table">Results table</h3>

<pre><code class="language-r">results
</code></pre>

<pre><code>##                 label   min    max      mean
## 1          1.6.1 Code 9.389 10.998 10.375667
## 2          2.0.0 Code 0.480  3.398  1.459333
## 3       2.0.0 Parquet 5.050  5.875  5.431000
## 4        2.0.0 In-Mem 6.900  8.311  7.611667
## 5      2.0.0 sparklyr 6.633  8.583  7.330000
## 6    2.0.0 SparkR SQL 6.935  7.874  7.300333
## 7 2.0.0 SparkR Native 6.750  7.226  6.973333
## 8               dplyr 3.123 16.016  7.578333
</code></pre>

		</div>
	</article>

	<div class="results" role="status" aria-live="polite">
		<div class="scrollable">
			<div class="wrapper">
				<div class="meta"></div>
				<div class="list"></div>
			</div>
		</div>
	</div>
</main>

    <script>
    
      var base_url = '';
      var repo_id  = '';
    
    </script>

    <script src="../../javascripts/application.js"></script>
    

    <script>
      
      var headers   = document.querySelectorAll('div.level2');
      var scrollspy = document.getElementById('scrollspy');

      if(scrollspy) {
        if(headers.length > 0) {
          for(var i = 0; i < headers.length; i++) {
            if(headers[i].id.length > 0){
              var li = document.createElement("li");
              li.setAttribute("class", "anchor");
              var a  = document.createElement("a");
              a.setAttribute("href", "#" + headers[i].id);
              a.setAttribute("title", headers[i].getElementsByTagName("h2")[0].innerHTM);
              a.innerHTML = headers[i].getElementsByTagName("h2")[0].innerHTML;
              li.appendChild(a)
              scrollspy.appendChild(li);
            }            
            
          }
        } else {
          scrollspy.parentElement.removeChild(scrollspy)
        }}
    </script>

    

    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.8.0/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
  </body>
</html>

