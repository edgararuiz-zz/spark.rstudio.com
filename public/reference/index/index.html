<p><p><a href="checkpoint_directory">checkpoint_directory</a> - Set/Get Spark checkpoint directory
<p><a href="compile_package_jars">compile_package_jars</a> - Compile Scala sources into a Java Archive (jar)
<p><a href="connection_config">connection_config</a> - Read configuration values for a connection
<p><a href="connection_is_open">connection_is_open</a> - Check whether the connection is open
<p><a href="connection_spark_shinyapp">connection_spark_shinyapp</a> - A Shiny app that can be used to construct a <code>spark_connect</code> statement
<p><a href="copy_to.spark_connection">copy_to.spark_connection</a> - Copy an R Data Frame to Spark
<p><a href="DBISparkResult-class">DBISparkResult-class</a> - DBI Spark Result.
<p><a href="download_scalac">download_scalac</a> - Downloads default Scala Compilers
<p><a href="ensure">ensure</a> - Enforce Specific Structure for R Objects
<p><a href="find_scalac">find_scalac</a> - Discover the Scala Compiler
<p><a href="ft_binarizer">ft_binarizer</a> - Feature Transformation &ndash; Binarizer
<p><a href="ft_bucketizer">ft_bucketizer</a> - Feature Transformation &ndash; Bucketizer
<p><a href="ft_count_vectorizer">ft_count_vectorizer</a> - Feature Tranformation &ndash; CountVectorizer
<p><a href="ft_discrete_cosine_transform">ft_discrete_cosine_transform</a> - Feature Transformation &ndash; Discrete Cosine Transform (DCT)
<p><a href="ft_elementwise_product">ft_elementwise_product</a> - Feature Transformation &ndash; ElementwiseProduct
<p><a href="ft_index_to_string">ft_index_to_string</a> - Feature Transformation &ndash; IndexToString
<p><a href="ft_one_hot_encoder">ft_one_hot_encoder</a> - Feature Transformation &ndash; OneHotEncoder
<p><a href="ft_quantile_discretizer">ft_quantile_discretizer</a> - Feature Transformation &ndash; QuantileDiscretizer
<p><a href="ft_regex_tokenizer">ft_regex_tokenizer</a> - Feature Tranformation &ndash; RegexTokenizer
<p><a href="ft_sql_transformer">ft_sql_transformer</a> - Feature Transformation &ndash; SQLTransformer
<p><a href="ft_string_indexer">ft_string_indexer</a> - Feature Transformation &ndash; StringIndexer
<p><a href="ft_tokenizer">ft_tokenizer</a> - Feature Tranformation &ndash; Tokenizer
<p><a href="ft_vector_assembler">ft_vector_assembler</a> - Feature Transformation &ndash; VectorAssembler
<p><a href="hive_context_config">hive_context_config</a> - Runtime configuration interface for Hive
<p><a href="invoke_method">invoke_method</a> - Generic call interface for spark shell
<p><a href="invoke">invoke</a> - Invoke a Method on a JVM Object
<p><a href="livy_config">livy_config</a> - Create a Spark Configuration for Livy
<p><a href="livy_install">livy_install</a> - Install Livy
<p><a href="livy_service">livy_service_start</a> - Start Livy
<p><a href="ml_als_factorization">ml_als_factorization</a> - Spark ML &ndash; Alternating Least Squares (ALS) matrix factorization.
<p><a href="ml_binary_classification_eval">ml_binary_classification_eval</a> - Spark ML - Binary Classification Evaluator
<p><a href="ml_classification_eval">ml_classification_eval</a> - Spark ML - Classification Evaluator
<p><a href="ml_create_dummy_variables">ml_create_dummy_variables</a> - Create Dummy Variables
<p><a href="ml_decision_tree">ml_decision_tree</a> - Spark ML &ndash; Decision Trees
<p><a href="ml_generalized_linear_regression">ml_generalized_linear_regression</a> - Spark ML &ndash; Generalized Linear Regression
<p><a href="ml_glm_tidiers">ml_glm_tidiers</a> - Tidying methods for Spark ML linear models
<p><a href="ml_gradient_boosted_trees">ml_gradient_boosted_trees</a> - Spark ML &ndash; Gradient-Boosted Tree
<p><a href="ml_lda">ml_lda</a> - Spark ML &ndash; Latent Dirichlet Allocation
<p><a href="ml_linear_regression">ml_linear_regression</a> - Spark ML &ndash; Linear Regression
<p><a href="ml_logistic_regression">ml_logistic_regression</a> - Spark ML &ndash; Logistic Regression
<p><a href="ml_model_data">ml_model_data</a> - Extracts data associated with a Spark ML model
<p><a href="ml_model">ml_model</a> - Create an ML Model Object
<p><a href="ml_multilayer_perceptron">ml_multilayer_perceptron</a> - Spark ML &ndash; Multilayer Perceptron
<p><a href="ml_naive_bayes">ml_naive_bayes</a> - Spark ML &ndash; Naive-Bayes
<p><a href="ml_one_vs_rest">ml_one_vs_rest</a> - Spark ML &ndash; One vs Rest
<p><a href="ml_options">ml_options</a> - Options for Spark ML Routines
<p><a href="ml_pca">ml_pca</a> - Spark ML &ndash; Principal Components Analysis
<p><a href="ml_prepare_dataframe">ml_prepare_dataframe</a> - Prepare a Spark DataFrame for Spark ML Routines
<p><a href="ml_prepare_inputs">ml_prepare_response_features_intercept</a> - Pre-process the Inputs to a Spark ML Routine
<p><a href="ml_random_forest">ml_random_forest</a> - Spark ML &ndash; Random Forests
<p><a href="ml_saveload">ml_saveload</a> - Save / Load a Spark ML Model Fit
<p><a href="ml_survival_regression">ml_survival_regression</a> - Spark ML &ndash; Survival Regression
<p><a href="ml_tree_feature_importance">ml_tree_feature_importance</a> - Spark ML - Feature Importance for Tree Models
<p><a href="na.replace">na.replace</a> - Replace Missing Values in Objects
<p><a href="pipe">%&gt;%</a> - Pipe operator
<p><a href="print_jobj">print_jobj</a> - Generic method for print jobj for a connection type
<p><a href="reexports">reexports</a> - Objects exported from other packages
<p><a href="register_extension">register_extension</a> - Register a Package that Implements a Spark Extension
<p><a href="sdf_along">sdf_along</a> - Create DataFrame for along Object
<p><a href="sdf_bind">sdf_bind</a> - Bind multiple Spark DataFrames by row and column
<p><a href="sdf_broadcast">sdf_broadcast</a> - Broadcast hint
<p><a href="sdf_checkpoint">sdf_checkpoint</a> - Checkpoint a Spark DataFrame
<p><a href="sdf_coalesce">sdf_coalesce</a> - Coalesces a Spark DataFrame
<p><a href="sdf_copy_to">sdf_copy_to</a> - Copy an Object into Spark
<p><a href="sdf_fast_bind_cols">sdf_fast_bind_cols</a> - Fast cbind for Spark DataFrames
<p><a href="sdf_last_index">sdf_last_index</a> - Returns the last index of a Spark DataFrame
<p><a href="sdf_len">sdf_len</a> - Create DataFrame for Length
<p><a href="sdf_mutate">sdf_mutate</a> - Mutate a Spark DataFrame
<p><a href="sdf_num_partitions">sdf_num_partitions</a> - Gets number of partitions of a Spark DataFrame
<p><a href="sdf_partition">sdf_partition</a> - Partition a Spark Dataframe
<p><a href="sdf_persist">sdf_persist</a> - Persist a Spark DataFrame
<p><a href="sdf_pivot">sdf_pivot</a> - Pivot a Spark DataFrame
<p><a href="sdf_predict">sdf_predict</a> - Model Predictions with Spark DataFrames
<p><a href="sdf_quantile">sdf_quantile</a> - Compute (Approximate) Quantiles with a Spark DataFrame
<p><a href="sdf_read_column">sdf_read_column</a> - Read a Column from a Spark DataFrame
<p><a href="sdf_register">sdf_register</a> - Register a Spark DataFrame
<p><a href="sdf_repartition">sdf_repartition</a> - Repartition a Spark DataFrame
<p><a href="sdf_residuals">sdf_residuals.ml_model_generalized_linear_regression</a> - Model Residuals
<p><a href="sdf_sample">sdf_sample</a> - Randomly Sample Rows from a Spark DataFrame
<p><a href="sdf_schema">sdf_schema</a> - Read the Schema of a Spark DataFrame
<p><a href="sdf_separate_column">sdf_separate_column</a> - Separate a Vector Column into Scalar Columns
<p><a href="sdf_seq">sdf_seq</a> - Create DataFrame for Range
<p><a href="sdf_sort">sdf_sort</a> - Sort a Spark DataFrame
<p><a href="sdf_with_sequential_id">sdf_with_sequential_id</a> - Add a Sequential ID Column to a Spark DataFrame
<p><a href="sdf_with_unique_id">sdf_with_unique_id</a> - Add a Unique ID Column to a Spark DataFrame
<p><a href="sdf-saveload">sdf-saveload</a> - Save / Load a Spark DataFrame
<p><a href="spark_apply">spark_apply</a> - Apply a Function in Spark
<p><a href="spark_compilation_spec">spark_compilation_spec</a> - Define a Spark Compilation Specification
<p><a href="spark_compile">spark_compile</a> - Compile Scala sources into a Java Archive
<p><a href="spark_config">spark_config</a> - Read Spark Configuration
<p><a href="spark_connection">spark_connection</a> - Retrieve the Spark Connection Associated with an R Object
<p><a href="spark_context_config">spark_context_config</a> - Runtime configuration interface for Spark.
<p><a href="spark_dataframe">spark_dataframe</a> - Retrieve a Spark DataFrame
<p><a href="spark_default_compilation_spec">spark_default_compilation_spec</a> - Default Compilation Specification for Spark Extensions
<p><a href="spark_default_version">spark_default_version</a> - determine the version that will be used by default if version is NULL
<p><a href="spark_dependency">spark_dependency</a> - Define a Spark dependency
<p><a href="spark_home_dir">spark_home_dir</a> - Find the SPARK_HOME directory for a version of Spark
<p><a href="spark_home_set">spark_home_set</a> - Set the SPARK_HOME environment variable
<p><a href="spark_install">spark_install</a> - Download and install various versions of Spark
<p><a href="spark_jobj">spark_jobj</a> - Retrieve a Spark JVM Object Reference
<p><a href="spark_load_table">spark_load_table</a> - Reads from a Spark Table into a Spark DataFrame.
<p><a href="spark_log">spark_log</a> - View Entries in the Spark Log
<p><a href="spark_read_csv">spark_read_csv</a> - Read a CSV file into a Spark DataFrame
<p><a href="spark_read_jdbc">spark_read_jdbc</a> - Read from JDBC connection into a Spark DataFrame.
<p><a href="spark_read_json">spark_read_json</a> - Read a JSON file into a Spark DataFrame
<p><a href="spark_read_parquet">spark_read_parquet</a> - Read a Parquet file into a Spark DataFrame
<p><a href="spark_read_source">spark_read_source</a> - Read from a generic source into a Spark DataFrame.
<p><a href="spark_read_table">spark_read_table</a> - Reads from a Spark Table into a Spark DataFrame.
<p><a href="spark_save_table">spark_save_table</a> - Saves a Spark DataFrame as a Spark table
<p><a href="spark_version_from_home">spark_version_from_home</a> - Get the Spark Version Associated with a Spark Installation
<p><a href="spark_version">spark_version</a> - Get the Spark Version Associated with a Spark Connection
<p><a href="spark_web">spark_web</a> - Open the Spark web interface
<p><a href="spark_write_csv">spark_write_csv</a> - Write a Spark DataFrame to a CSV
<p><a href="spark_write_json">spark_write_json</a> - Write a Spark DataFrame to a JSON file
<p><a href="spark_write_parquet">spark_write_parquet</a> - Write a Spark DataFrame to a Parquet file
<p><a href="spark_write_table">spark_write_table</a> - Writes a Spark DataFrame into a Spark table
<p><a href="spark-api">spark-api</a> - Access the Spark API
<p><a href="spark-connections">spark-connections</a> - Manage Spark Connections
<p><a href="src_databases">src_databases</a> - Show database list
<p><a href="tbl_cache">tbl_cache</a> - Cache a Spark Table
<p><a href="tbl_change_db">tbl_change_db</a> - Use specific database
<p><a href="tbl_uncache">tbl_uncache</a> - Uncache a Spark Table
<p><a href="top_n">top_n</a> - Select top (or bottom) n rows (by value)</p>
