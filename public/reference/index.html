<!DOCTYPE html>
  
  
  
  
   <html class="no-js"> 

  <head lang="en-us">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,maximum-scale=1">
    <meta http-equiv="X-UA-Compatible" content="IE=10" />
   <link rel="stylesheet" href="../stylesheets/bootstrap.min.css">
    <title> - sparklyr: R interface for Apache Spark</title>
    <meta name="generator" content="Hugo 0.20" />

    
    <meta name="description" content="A website built through Hugo and blogdown (and gitdown).">
    
    <link rel="canonical" href="../reference/">
    

    <meta property="og:url" content="/reference/">
    <meta property="og:title" content="sparklyr: R interface for Apache Spark">
    <meta property="og:image" content="">
    <meta name="apple-mobile-web-app-title" content="sparklyr: R interface for Apache Spark">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

    <link rel="shortcut icon" type="image/x-icon" href="../images/favicon.ico">
    <link rel="icon" type="image/x-icon" href="../images/favicon.ico">

    <link rel="stylesheet" href="../stylesheets/fonts.css">
    <link rel="stylesheet" href="../stylesheets/application.css">
    <link rel="stylesheet" href="../stylesheets/temporary.css">
    <link rel="stylesheet" href="../stylesheets/palettes.css">
    <link rel="stylesheet" href="../stylesheets/highlight/highlight.css">

    
    
    
    <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Roboto:400,700|Roboto&#43;Mono">
    <style>
      body, input {
        font-family: 'Roboto', Helvetica, Arial, sans-serif;
      }
      pre, code {
        font-family: 'Roboto Mono', 'Courier New', 'Courier', monospace;
      }
    </style>

    
    <script src="../javascripts/modernizr.js"></script>

    
    <link href="../reference/index.xml" rel="alternate" type="application/rss+xml" title="sparklyr: R interface for Apache Spark" />
    <link href="../reference/index.xml" rel="feed" type="application/rss+xml" title="sparklyr: R interface for Apache Spark" />
    

  </head>
  <body class="palette-primary-rstudio-dark palette-accent-orange">




<div class="backdrop">
	<div class="backdrop-paper"></div>
</div>

<input class="toggle" type="checkbox" id="toggle-drawer">
<input class="toggle" type="checkbox" id="toggle-search">
<label class="toggle-button overlay" for="toggle-drawer"></label>

<header class="header">
	
  <div class="bar default">
    <div class="button button-menu" role="button" aria-label="Menu">
      <label class="toggle-button icon icon-menu" for="toggle-drawer">
        <span></span>
      </label>
    </div>

    <div>
      <h1><a href="../">sparklyr: R interface for Apache Spark</a></h1>
    </div>


    
    <div class="button button-twitter" role="button" aria-label="Twitter">
       <a href="https://twitter.com/rstudio" title="@rstudio on Twitter" target="_blank" class="toggle-button icon icon-twitter"></a>
    </div>
    

    
    <div class="button button-github" role="button" aria-label="GitHub">
      <a href="https://github.com/rstudio/sparklyr" title="@rstudio/sparklyr on GitHub" target="_blank" class="toggle-button icon icon-github"></a>
    </div>
    
    
   </div>

</header>

<main class="main">
	<div class="drawer">
		<nav aria-label="Navigation">

  <div class="scrollable">
    <div class="wrapper">
      

      <div class="toc">
        
        <ul>
          





<li>
  
    



<a class="current" title="Reference" href="../reference/">
	
	Reference
</a>

<ul id="scrollspy">
</ul>


  
</li>



<li>
  
    



<a  title="Documents" href="../documents/">
	
	Documents
</a>


  
</li>



<li>
  
    



<a  title="News" href="../news/">
	
	News
</a>


  
</li>


        </ul>
        

        
      </div>
    </div>
  </div>
</nav>

	</div>

	<article class="article">
		<div class="wrapper">
		  
		  <h1> </h1>
			<p><h1>Function Reference</h1>
<p><a href="checkpoint_directory">checkpoint_directory</a> - Set/Get Spark checkpoint directory
<p><a href="compile_package_jars">compile_package_jars</a> - Compile Scala sources into a Java Archive (jar)
<p><a href="connection_config">connection_config</a> - Read configuration values for a connection
<p><a href="connection_is_open">connection_is_open</a> - Check whether the connection is open
<p><a href="connection_spark_shinyapp">connection_spark_shinyapp</a> - A Shiny app that can be used to construct a <code>spark_connect</code> statement
<p><a href="copy_to.spark_connection">copy_to.spark_connection</a> - Copy an R Data Frame to Spark
<p><a href="DBISparkResult-class">DBISparkResult-class</a> - DBI Spark Result.
<p><a href="download_scalac">download_scalac</a> - Downloads default Scala Compilers
<p><a href="ensure">ensure</a> - Enforce Specific Structure for R Objects
<p><a href="find_scalac">find_scalac</a> - Discover the Scala Compiler
<p><a href="ft_binarizer">ft_binarizer</a> - Feature Transformation &ndash; Binarizer
<p><a href="ft_bucketizer">ft_bucketizer</a> - Feature Transformation &ndash; Bucketizer
<p><a href="ft_count_vectorizer">ft_count_vectorizer</a> - Feature Tranformation &ndash; CountVectorizer
<p><a href="ft_discrete_cosine_transform">ft_discrete_cosine_transform</a> - Feature Transformation &ndash; Discrete Cosine Transform (DCT)
<p><a href="ft_elementwise_product">ft_elementwise_product</a> - Feature Transformation &ndash; ElementwiseProduct
<p><a href="ft_one_hot_encoder">ft_one_hot_encoder</a> - Feature Transformation &ndash; OneHotEncoder
<p><a href="ft_quantile_discretizer">ft_quantile_discretizer</a> - Feature Transformation &ndash; QuantileDiscretizer
<p><a href="ft_regex_tokenizer">ft_regex_tokenizer</a> - Feature Tranformation &ndash; RegexTokenizer
<p><a href="ft_sql_transformer">ft_sql_transformer</a> - Feature Transformation &ndash; SQLTransformer
<p><a href="ft_tokenizer">ft_tokenizer</a> - Feature Tranformation &ndash; Tokenizer
<p><a href="ft_vector_assembler">ft_vector_assembler</a> - Feature Transformation &ndash; VectorAssembler
<p><a href="hive_context_config">hive_context_config</a> - Runtime configuration interface for Hive
<p><a href="invoke_method">invoke_method</a> - Generic call interface for spark shell
<p><a href="invoke">invoke</a> - Invoke a Method on a JVM Object
<p><a href="livy_config">livy_config</a> - Create a Spark Configuration for Livy
<p><a href="livy_install">livy_install</a> - Install Livy
<p><a href="livy_service">livy_service_start</a> - Start Livy
<p><a href="ml_als_factorization">ml_als_factorization</a> - Spark ML &ndash; Alternating Least Squares (ALS) matrix factorization.
<p><a href="ml_binary_classification_eval">ml_binary_classification_eval</a> - Spark ML - Binary Classification Evaluator
<p><a href="ml_classification_eval">ml_classification_eval</a> - Spark ML - Classification Evaluator
<p><a href="ml_create_dummy_variables">ml_create_dummy_variables</a> - Create Dummy Variables
<p><a href="ml_decision_tree">ml_decision_tree</a> - Spark ML &ndash; Decision Trees
<p><a href="ml_generalized_linear_regression">ml_generalized_linear_regression</a> - Spark ML &ndash; Generalized Linear Regression
<p><a href="ml_glm_tidiers">ml_glm_tidiers</a> - Tidying methods for Spark ML linear models
<p><a href="ml_gradient_boosted_trees">ml_gradient_boosted_trees</a> - Spark ML &ndash; Gradient-Boosted Tree
<p><a href="ml_lda">ml_lda</a> - Spark ML &ndash; Latent Dirichlet Allocation
<p><a href="ml_linear_regression">ml_linear_regression</a> - Spark ML &ndash; Linear Regression
<p><a href="ml_logistic_regression">ml_logistic_regression</a> - Spark ML &ndash; Logistic Regression
<p><a href="ml_model_data">ml_model_data</a> - Extracts data associated with a Spark ML model
<p><a href="ml_model">ml_model</a> - Create an ML Model Object
<p><a href="ml_multilayer_perceptron">ml_multilayer_perceptron</a> - Spark ML &ndash; Multilayer Perceptron
<p><a href="ml_naive_bayes">ml_naive_bayes</a> - Spark ML &ndash; Naive-Bayes
<p><a href="ml_one_vs_rest">ml_one_vs_rest</a> - Spark ML &ndash; One vs Rest
<p><a href="ml_options">ml_options</a> - Options for Spark ML Routines
<p><a href="ml_pca">ml_pca</a> - Spark ML &ndash; Principal Components Analysis
<p><a href="ml_prepare_dataframe">ml_prepare_dataframe</a> - Prepare a Spark DataFrame for Spark ML Routines
<p><a href="ml_prepare_inputs">ml_prepare_response_features_intercept</a> - Pre-process the Inputs to a Spark ML Routine
<p><a href="ml_random_forest">ml_random_forest</a> - Spark ML &ndash; Random Forests
<p><a href="ml_saveload">ml_saveload</a> - Save / Load a Spark ML Model Fit
<p><a href="ml_survival_regression">ml_survival_regression</a> - Spark ML &ndash; Survival Regression
<p><a href="ml_tree_feature_importance">ml_tree_feature_importance</a> - Spark ML - Feature Importance for Tree Models
<p><a href="na.replace">na.replace</a> - Replace Missing Values in Objects
<p><a href="pipe">%&gt;%</a> - Pipe operator
<p><a href="print_jobj">print_jobj</a> - Generic method for print jobj for a connection type
<p><a href="reexports">reexports</a> - Objects exported from other packages
<p><a href="register_extension">register_extension</a> - Register a Package that Implements a Spark Extension
<p><a href="sdf_along">sdf_along</a> - Create DataFrame for along Object
<p><a href="sdf_bind">sdf_bind</a> - Bind multiple Spark DataFrames by row and column
<p><a href="sdf_broadcast">sdf_broadcast</a> - Broadcast hint
<p><a href="sdf_checkpoint">sdf_checkpoint</a> - Checkpoint a Spark DataFrame
<p><a href="sdf_coalesce">sdf_coalesce</a> - Coalesces a Spark DataFrame
<p><a href="sdf_copy_to">sdf_copy_to</a> - Copy an Object into Spark
<p><a href="sdf_fast_bind_cols">sdf_fast_bind_cols</a> - Fast cbind for Spark DataFrames
<p><a href="sdf_len">sdf_len</a> - Create DataFrame for Length
<p><a href="sdf_mutate">sdf_mutate</a> - Mutate a Spark DataFrame
<p><a href="sdf_num_partitions">sdf_num_partitions</a> - Gets number of partitions of a Spark DataFrame
<p><a href="sdf_partition">sdf_partition</a> - Partition a Spark Dataframe
<p><a href="sdf_persist">sdf_persist</a> - Persist a Spark DataFrame
<p><a href="sdf_pivot">sdf_pivot</a> - Pivot a Spark DataFrame
<p><a href="sdf_predict">sdf_predict</a> - Model Predictions with Spark DataFrames
<p><a href="sdf_quantile">sdf_quantile</a> - Compute (Approximate) Quantiles with a Spark DataFrame
<p><a href="sdf_read_column">sdf_read_column</a> - Read a Column from a Spark DataFrame
<p><a href="sdf_register">sdf_register</a> - Register a Spark DataFrame
<p><a href="sdf_repartition">sdf_repartition</a> - Repartition a Spark DataFrame
<p><a href="sdf_residuals">sdf_residuals.ml_model_generalized_linear_regression</a> - Model Residuals
<p><a href="sdf_sample">sdf_sample</a> - Randomly Sample Rows from a Spark DataFrame
<p><a href="sdf_schema">sdf_schema</a> - Read the Schema of a Spark DataFrame
<p><a href="sdf_separate_column">sdf_separate_column</a> - Separate a Vector Column into Scalar Columns
<p><a href="sdf_seq">sdf_seq</a> - Create DataFrame for Range
<p><a href="sdf_sort">sdf_sort</a> - Sort a Spark DataFrame
<p><a href="sdf_with_sequential_id">sdf_with_sequential_id</a> - Add a Sequential ID Column to a Spark DataFrame
<p><a href="sdf_with_unique_id">sdf_with_unique_id</a> - Add a Unique ID Column to a Spark DataFrame
<p><a href="sdf-saveload">sdf-saveload</a> - Save / Load a Spark DataFrame
<p><a href="spark_apply">spark_apply</a> - Apply a Function in Spark
<p><a href="spark_compilation_spec">spark_compilation_spec</a> - Define a Spark Compilation Specification
<p><a href="spark_compile">spark_compile</a> - Compile Scala sources into a Java Archive
<p><a href="spark_config">spark_config</a> - Read Spark Configuration
<p><a href="spark_connection">spark_connection</a> - Retrieve the Spark Connection Associated with an R Object
<p><a href="spark_context_config">spark_context_config</a> - Runtime configuration interface for Spark.
<p><a href="spark_dataframe">spark_dataframe</a> - Retrieve a Spark DataFrame
<p><a href="spark_default_compilation_spec">spark_default_compilation_spec</a> - Default Compilation Specification for Spark Extensions
<p><a href="spark_default_version">spark_default_version</a> - determine the version that will be used by default if version is NULL
<p><a href="spark_dependency">spark_dependency</a> - Define a Spark dependency
<p><a href="spark_home_dir">spark_home_dir</a> - Find the SPARK_HOME directory for a version of Spark
<p><a href="spark_home_set">spark_home_set</a> - Set the SPARK_HOME environment variable
<p><a href="spark_install">spark_install</a> - Download and install various versions of Spark
<p><a href="spark_jobj">spark_jobj</a> - Retrieve a Spark JVM Object Reference
<p><a href="spark_load_table">spark_load_table</a> - Reads from a Spark Table into a Spark DataFrame.
<p><a href="spark_log">spark_log</a> - View Entries in the Spark Log
<p><a href="spark_read_csv">spark_read_csv</a> - Read a CSV file into a Spark DataFrame
<p><a href="spark_read_jdbc">spark_read_jdbc</a> - Read from JDBC connection into a Spark DataFrame.
<p><a href="spark_read_json">spark_read_json</a> - Read a JSON file into a Spark DataFrame
<p><a href="spark_read_parquet">spark_read_parquet</a> - Read a Parquet file into a Spark DataFrame
<p><a href="spark_read_source">spark_read_source</a> - Read from a generic source into a Spark DataFrame.
<p><a href="spark_read_table">spark_read_table</a> - Reads from a Spark Table into a Spark DataFrame.
<p><a href="spark_save_table">spark_save_table</a> - Saves a Spark DataFrame as a Spark table
<p><a href="spark_version_from_home">spark_version_from_home</a> - Get the Spark Version Associated with a Spark Installation
<p><a href="spark_version">spark_version</a> - Get the Spark Version Associated with a Spark Connection
<p><a href="spark_web">spark_web</a> - Open the Spark web interface
<p><a href="spark_write_csv">spark_write_csv</a> - Write a Spark DataFrame to a CSV
<p><a href="spark_write_json">spark_write_json</a> - Write a Spark DataFrame to a JSON file
<p><a href="spark_write_parquet">spark_write_parquet</a> - Write a Spark DataFrame to a Parquet file
<p><a href="spark_write_table">spark_write_table</a> - Writes a Spark DataFrame into a Spark table
<p><a href="spark-api">spark-api</a> - Access the Spark API
<p><a href="spark-connections">spark-connections</a> - Manage Spark Connections
<p><a href="src_databases">src_databases</a> - Show database list
<p><a href="tbl_cache">tbl_cache</a> - Cache a Spark Table
<p><a href="tbl_change_db">tbl_change_db</a> - Use specific database
<p><a href="tbl_uncache">tbl_uncache</a> - Uncache a Spark Table
<p><a href="top_n">top_n</a> - Select top (or bottom) n rows (by value)</p>

			

		</div>
	</article>

	<div class="results" role="status" aria-live="polite">
		<div class="scrollable">
			<div class="wrapper">
				<div class="meta"></div>
				<div class="list"></div>
			</div>
		</div>
	</div>
</main>

    <script>
    
      var base_url = '';
      var repo_id  = '';
    
    </script>

    <script src="../javascripts/application.js"></script>
    

    <script>
      
      var headers   = document.querySelectorAll('div.level2');
      var scrollspy = document.getElementById('scrollspy');

      if(scrollspy) {
        if(headers.length > 0) {
          for(var i = 0; i < headers.length; i++) {
            if(headers[i].id.length > 0){
              var li = document.createElement("li");
              li.setAttribute("class", "anchor");
              var a  = document.createElement("a");
              a.setAttribute("href", "#" + headers[i].id);
              a.setAttribute("title", headers[i].getElementsByTagName("h2")[0].innerHTM);
              a.innerHTML = headers[i].getElementsByTagName("h2")[0].innerHTML;
              li.appendChild(a)
              scrollspy.appendChild(li);
            }            
            
          }
        } else {
          scrollspy.parentElement.removeChild(scrollspy)
        }}
    </script>

    

    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.8.0/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
  </body>
</html>

